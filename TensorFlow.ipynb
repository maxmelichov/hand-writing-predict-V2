{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pickletools import optimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) =mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_eval,y_train,y_eval= train_test_split(x_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ANNmodel():\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer= \"Nadam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums= range(128,480,64)\n",
    "val_loss= np.inf\n",
    "val_acc=0\n",
    "num = 0\n",
    "for i in range(1,6,2):\n",
    "    # for val in nums:\n",
    "        model = ANNmodel()\n",
    "        model.fit(x_train,y_train,epochs=i,batch_size=32)\n",
    "        loss,acc = model.evaluate(x_eval,y_eval)\n",
    "        if loss <val_loss and acc >val_acc:\n",
    "            model.save(\"best_ANNmodel1.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "   model = tf.keras.models.Sequential()\n",
    "\n",
    "   model.add(tf.keras.layers.Conv2D(hp.Int('input_units',min_value=32, max_value=256,step =32), (3, 3), input_shape=(28,28,1)))\n",
    "   model.add(tf.keras.layers.Activation('relu'))\n",
    "   model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) \n",
    "   for i in range(hp.Int(\"n_layers\",1,4)):\n",
    "      model.add(tf.keras.layers.Conv2D(hp.Int(f'conv_{i}_units',min_value=32, max_value=256,step =32), (3, 3)))\n",
    "      model.add(tf.keras.layers.Activation('relu'))\n",
    "   model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))   \n",
    "\n",
    "   model.add(tf.keras.layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors \n",
    "   model.add(tf.keras.layers.Dense(10))\n",
    "   model.add(tf.keras.layers.Activation(\"softmax\"))    \n",
    "   model.compile(optimizer=\"adam\",\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"])\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 03s]\n",
      "val_accuracy: 0.9862499833106995\n",
      "\n",
      "Best val_accuracy So Far: 0.9899166822433472\n",
      "Total elapsed time: 00h 02m 54s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from msilib.schema import Directory\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameter\n",
    "import time\n",
    "# LOG_DIR = f\"{int(time.time())}\"\n",
    "tuner= RandomSearch(build_model,objective='val_accuracy',max_trials=3)\n",
    "tuner.search(x=x_train,y=y_train,epochs=50,batch_size=32,validation_data=(x_eval,y_eval),callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2, restore_best_weights = True)],verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 96, 'n_layers': 2, 'conv_0_units': 96, 'conv_1_units': 96}\n",
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000020B5333BA60>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 96\n",
      "n_layers: 2\n",
      "conv_0_units: 96\n",
      "conv_1_units: 96\n",
      "Score: 0.9899166822433472\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 64\n",
      "n_layers: 3\n",
      "conv_0_units: 32\n",
      "conv_1_units: 224\n",
      "conv_2_units: 32\n",
      "Score: 0.9862499833106995\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 64\n",
      "n_layers: 2\n",
      "conv_0_units: 224\n",
      "conv_1_units: 32\n",
      "Score: 0.9851666688919067\n",
      "None\n",
      "<keras.engine.sequential.Sequential object at 0x0000020A8C452580>\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "print(tuner.get_best_models()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
    "\n",
    "def CNNmodel():\n",
    "   model =  tf.keras.models.Sequential()\n",
    "   model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1)))\n",
    "   model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "   model.add(Dropout(0.25))\n",
    "   model.add(Flatten())\n",
    "   model.add(Dense(256, activation='relu'))\n",
    "   model.add(Dropout(0.5))\n",
    "   model.add(Dense(10, activation='softmax'))\n",
    "   model.compile(loss='sparse_categorical_crossentropy',optimizer='Nadam',metrics=['accuracy'])\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualiztion(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualiztion(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss= np.inf\n",
    "val_acc=0\n",
    "num = 0\n",
    "for i in range(3,11,2):\n",
    "   # for val in nums:\n",
    "   modelCNN = CNNmodel()\n",
    "   x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "   x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "   modelCNN.fit(x_train,y_train,epochs=i,batch_size=64)\n",
    "   loss,acc = modelCNN.evaluate(x_eval,y_eval)\n",
    "   if loss <val_loss and acc >val_acc:\n",
    "        modelCNN.save(\"best_CNNmodel1.model\")\n",
    "        val_loss=loss\n",
    "        val_acc=val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('best_ANNmodel1.model')\n",
    "new_loss,new_acc = new_model.evaluate(x_test,y_test)\n",
    "print(f\"Best lost: {new_loss}, Best acc: {new_acc}, Best Number neurons: {512}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('best_CNNmodel1.model')\n",
    "new_loss,new_acc = new_model.evaluate(x_test,y_test)\n",
    "print(f\"Best lost: {new_loss}, Best acc: {new_acc}, Best Number neurons: {64}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "DATADIR=r'D:\\sign to english\\Youtube class\\kagglecatsanddogs_5340\\PetImages'\n",
    "Categories = ['Dog','Cat']\n",
    "for cate in Categories:\n",
    "    path=os.path.join(DATADIR,cate)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        # plt.imshow(img_array,cmap='gray')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE= 50\n",
    "new_array =cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, rankdir=\"LR\", show_shapes=False, show_layer_names=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TensorFlow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7842d1971238c40bc91f0e3c4b1f67715db27be3d2f267cdf8f729dc15e9bd8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
